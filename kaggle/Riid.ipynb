{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport time\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nfrom sklearn.metrics import roc_auc_score\nimport riiideducation\nfrom tqdm import tqdm\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.chdir('/kaggle/input/riiid-test-answer-prediction/')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#import data\ntrain = pd.read_csv('train.csv', nrows=10**6)\ntest = pd.read_csv(\"example_test.csv\")\nlectures = pd.read_csv(\"lectures.csv\")\nquestions = pd.read_csv(\"questions.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"#preprocessing\ntrain[['prior_question_had_explanation']]=train[['prior_question_had_explanation']].replace(False,0).replace(True,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainQ = train[train['answered_correctly'] != -1]\ntrainLec = train[train['answered_correctly'] == -1]\ndef correctRatio(content_id:int) -> float: \n    global trainQ\n    temp = trainQ[trainQ['content_id']==content_id]\n    if(len(temp)== 0):\n        return (-1,-1)\n    return (temp['answered_correctly'].mean(), len(temp))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cr = [] #correct_ratio\ncn = [] #sample num\n    \nfor i in tqdm(questions['question_id']):\n    r,n = correctRatio(i)\n    cr.append(r)\n    cn.append(n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"questions['sample_num'] = cn\nquestions['correct_ratio'] = cr\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.apply(lambda x:x['tags'].split(),axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"questions[questions.apply(lambda x:type(x['tags']),axis=1)==float]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"questions.loc[questions.isna()['tags'],'tags'] = '-1'\n\nquestions['tags_list'] = questions.apply(lambda x:x['tags'].split(),axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"questionsValid = questions[(questions['correct_ratio'] !=-1) & (questions['sample_num']>=10)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"questionsValid.sort_values(\"correct_ratio\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def tagRatio(tagsDic,arr, n):\n    temp = []\n    for i in arr:\n        i = tagsDic[i]\n        if(i[1]>=n):\n            temp.append(i[0])\n            \n    if(len(temp)==0):\n        return -1\n    else:\n        return np.mean(temp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def getanswerRatioByTags(user_id):\n    \n    df = trainQ[trainQ['user_id']==user_id]\n\n    temp = questions[['question_id','tags_list']]\n\n    temp.columns = ['content_id','tags_list']\n\n    df = df.merge(temp,how='left', on='content_id')\n\n    tags = set(df['tags_list'].sum())\n\n    tagsDic = {}\n    for tag in tags:\n        tagsDic[tag]=[]\n\n    \n\n  \n    for i in range(len(df)):\n        for j in df.iloc[i,10]:\n            tagsDic[j].append(df.iloc[i,7])\n\n    for k,v in tagsDic.items():\n        tagsDic[k] = (np.mean(v),len(v))\n\n    df['answer_ratio_by_tag'] = df.apply(lambda x:tagRatio(tagsDic,x['tags_list'],10),axis=1)\n    return df[['user_id','content_id','timestamp','task_container_id','answer_ratio_by_tag']]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = pd.DataFrame()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for user_id in tqdm(trainQ['user_id'].unique()):\n    X = X.append(getanswerRatioByTags(user_id))\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"usrCorrect = trainQ[['user_id','answered_correctly']].groupby(\"user_id\").mean()\nproblemCorrect = trainQ[['content_id','answered_correctly']].groupby(\"content_id\").mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"z = X.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = z.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = trainQ.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X[['timestamp']] = np.log(X[['timestamp']]+1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X[['task_container_id']] = np.log(X[['task_container_id']]+1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#using all elements\nX = X.merge(usrCorrect.reset_index(), how='left',on='user_id')\n\nX = X.merge(problemCorrect.reset_index(), how='left',on ='content_id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = X[['answer_ratio_by_tag','answered_correctly_x','answered_correctly_y']]\nX.columns = ['tag','user','problem']\ny = trainQ['answered_correctly']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = X[['timestamp','task_container_id','answer_ratio_by_tag','answered_correctly_x','answered_correctly_y']]\nX.columns = ['timestamp','task_container_id','tag','user','problem']\ny = trainQ['answered_correctly']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = X[['answered_correctly_y','answered_correctly']]\nX.columns = ['user','problem']\ny = trainQ['answered_correctly']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.loc[X['tag']==-1,'tag'] = X.loc[X['tag']==-1,'user']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from  sklearn.linear_model import LogisticRegression\nfrom  sklearn.model_selection import train_test_split\nXt, Xv, Yt, Yv = train_test_split(X, y, test_size =0.2, shuffle=True)\n\nReg = LogisticRegression()\nReg.fit(Xt, np.array(Yt))\n\ny_pred = Reg.predict_proba(Xv)[:,1]\n#y_pred = np.array(Xv['answered_correctly_content'])\ny_true = np.array(Yv)\n\nroc_auc_score(y_true, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## lgbm 모델, 결과가 좋지않아 사용안함\n# import lightgbm as lgb\n\n# train_ds = lgb.Dataset(Xt, label = Yt) \n# test_ds = lgb.Dataset(Xv, label = Yv) \n\n# params = {'learning_rate': 0.01, \n#           'max_depth': 16, \n#           'boosting': 'gbdt', \n#           'objective': 'binary', \n#           'metric': 'auc', \n#           'is_training_metric': True, \n#           'num_leaves': 144, \n#           'feature_fraction': 0.9, \n#           'bagging_fraction': 0.7, \n#           'bagging_freq': 5, \n#           'seed':2021}\n\n# model = lgb.train(params, train_ds, 1000, test_ds, verbose_eval=100, early_stopping_rounds=100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nsns.distplot(train.groupby(\"user_id\").count()).set_title(\"The number of contents per id\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"valid varialbe I think<br>\n- user_id and content_id(base)\n- timestamp or task_container_id\n- prior_question_had_explanation\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['timestamp_log'] = np.log(train['timestamp']+1)\ntrain['task_container_id_log'] = np.log(train['task_container_id']+1)\n\ntrain[train['answered_correctly']!=-1].corr()['answered_correctly']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"usrCorrect = train[['user_id','answered_correctly']].groupby(\"user_id\").mean()\nproblemCorrect = train[['content_id','answered_correctly']].groupby(\"content_id\").mean()\n\nnp.random.seed(2020)\nX = train.sample(10**7)\n\n#using all elements\nX = X.merge(usrCorrect.reset_index(), on='user_id')\n\nX = X.merge(problemCorrect.reset_index(), on ='content_id')\n\nX = X[['answered_correctly_y','answered_correctly','answered_correctly_x']]\nX = X[X['answered_correctly_x'] != -1]\nX.columns = ['usr','problem','y']\ny = X['y']\nX = X.iloc[:,:-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# #using last element(tail)\n# X = train.groupby([\"user_id\")\n\n# X = X[X['answered_correctly'] != -1]\n\n# X = X.merge(usrCorrect.reset_index(), on='user_id')\n\n# X = X.merge(problemCorrect.reset_index(), on='content_id')\n\n# y = X['answered_correctly_x']\n\n# X = X[['answered_correctly_y','answered_correctly']]\n\n\n# X.columns  = ['usr','problem']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Modeling"},{"metadata":{"trusted":true},"cell_type":"code","source":"from  sklearn.linear_model import LogisticRegression\nfrom  sklearn.model_selection import train_test_split\nXt, Xv, Yt, Yv = train_test_split(X, y, test_size =0.2, shuffle=False)\n\nReg = LogisticRegression()\nReg.fit(Xt, np.array(Yt))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reg.predict_proba(Xv)[:,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = Reg.predict_proba(Xv)[:,1]\n#y_pred = np.array(Xv['answered_correctly_content'])\ny_true = np.array(Yv)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Reg.coef_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"roc_auc_score(y_true, y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Predict"},{"metadata":{"trusted":true},"cell_type":"code","source":"env = riiideducation.make_env()\n\niter_test = env.iter_test()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"iter_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for (test, sample_prediction_df) in iter_test:\n    #uid = test['user_id']\n\n    test = test.merge(usrCorrect.reset_index(), on='user_id', how='left')\n    test = test.merge(problemCorrect.reset_index(), on='content_id', how='left')\n\n    XTest = test[['answered_correctly_x','answered_correctly_y']]\n\n    XTest.columns = ['usr','problem']\n\n    XTest=XTest.fillna(0.5)\n\n    output = Reg.predict_proba(XTest)[:,1]\n\n    test['answered_correctly'] = output\n    \n    env.predict(test.loc[test['content_type_id']==0, ['row_id', 'answered_correctly']])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}