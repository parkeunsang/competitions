{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "88b17b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8f228236",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.utils.data import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8ba971a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(pred, y):\n",
    "    return np.sqrt(sum((pred-y)**2)/len(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19511130",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae7ea140",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c1eb48c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_appeared = []\n",
    "for smiles in train['SMILES']:\n",
    "    smiles_splited = list(smiles)  # 'Cc1n' --> ['C', 'c', '1', 'n']\n",
    "    tokens_appeared.extend(smiles_splited)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f627a168",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_counter = Counter(tokens_appeared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bf4e437b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9040c9da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>MLM</th>\n",
       "      <th>HLM</th>\n",
       "      <th>AlogP</th>\n",
       "      <th>Molecular_Weight</th>\n",
       "      <th>Num_H_Acceptors</th>\n",
       "      <th>Num_H_Donors</th>\n",
       "      <th>Num_RotatableBonds</th>\n",
       "      <th>LogD</th>\n",
       "      <th>Molecular_PolarSurfaceArea</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_0000</td>\n",
       "      <td>CCOc1ccc(CNC(=O)c2cc(-c3sc(C)nc3C)n[nH]2)cc1OCC</td>\n",
       "      <td>26.010</td>\n",
       "      <td>50.680</td>\n",
       "      <td>3.259</td>\n",
       "      <td>400.495</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3.259</td>\n",
       "      <td>117.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_0001</td>\n",
       "      <td>Cc1nc(C)c(CN2CC(C)C(=O)Nc3ccccc32)s1</td>\n",
       "      <td>29.270</td>\n",
       "      <td>50.590</td>\n",
       "      <td>2.169</td>\n",
       "      <td>301.407</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.172</td>\n",
       "      <td>73.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_0002</td>\n",
       "      <td>CCCN1CCN(c2nn3nnnc3c3ccccc23)CC1</td>\n",
       "      <td>5.586</td>\n",
       "      <td>80.892</td>\n",
       "      <td>1.593</td>\n",
       "      <td>297.358</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.585</td>\n",
       "      <td>62.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_0003</td>\n",
       "      <td>Cc1ccc(-c2ccc(-n3nc(C)c(S(=O)(=O)N4CCN(C5CCCCC...</td>\n",
       "      <td>5.710</td>\n",
       "      <td>2.000</td>\n",
       "      <td>4.771</td>\n",
       "      <td>494.652</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3.475</td>\n",
       "      <td>92.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_0004</td>\n",
       "      <td>Cc1ccc2c(c1)N(C(=O)c1ccncc1)CC(C)O2</td>\n",
       "      <td>93.270</td>\n",
       "      <td>99.990</td>\n",
       "      <td>2.335</td>\n",
       "      <td>268.310</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.337</td>\n",
       "      <td>42.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3493</th>\n",
       "      <td>TRAIN_3493</td>\n",
       "      <td>Cn1nc(CNC(=O)Cn2nc(C(F)(F)F)c3c2CCC3)c(Cl)c1Cl</td>\n",
       "      <td>1.556</td>\n",
       "      <td>3.079</td>\n",
       "      <td>3.409</td>\n",
       "      <td>396.195</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3.409</td>\n",
       "      <td>64.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3494</th>\n",
       "      <td>TRAIN_3494</td>\n",
       "      <td>CCn1[nH]cc/c1=N\\C(=O)c1nn(-c2ccccc2)c(=O)c2ccc...</td>\n",
       "      <td>35.560</td>\n",
       "      <td>47.630</td>\n",
       "      <td>1.912</td>\n",
       "      <td>359.381</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.844</td>\n",
       "      <td>77.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3495</th>\n",
       "      <td>TRAIN_3495</td>\n",
       "      <td>CCOC(=O)CCCc1nc2cc(N)ccc2n1C</td>\n",
       "      <td>56.150</td>\n",
       "      <td>1.790</td>\n",
       "      <td>1.941</td>\n",
       "      <td>261.320</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2.124</td>\n",
       "      <td>70.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3496</th>\n",
       "      <td>TRAIN_3496</td>\n",
       "      <td>Nc1cc(C(=O)OCCC2CCOC2=O)cnc1Cl</td>\n",
       "      <td>0.030</td>\n",
       "      <td>2.770</td>\n",
       "      <td>0.989</td>\n",
       "      <td>284.696</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.989</td>\n",
       "      <td>91.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3497</th>\n",
       "      <td>TRAIN_3497</td>\n",
       "      <td>COc1ccc(-c2nc(Cc3ccccc3)sc2C)cc1</td>\n",
       "      <td>0.450</td>\n",
       "      <td>2.650</td>\n",
       "      <td>4.321</td>\n",
       "      <td>295.399</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.321</td>\n",
       "      <td>50.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3498 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                             SMILES     MLM  \\\n",
       "0     TRAIN_0000    CCOc1ccc(CNC(=O)c2cc(-c3sc(C)nc3C)n[nH]2)cc1OCC  26.010   \n",
       "1     TRAIN_0001               Cc1nc(C)c(CN2CC(C)C(=O)Nc3ccccc32)s1  29.270   \n",
       "2     TRAIN_0002                   CCCN1CCN(c2nn3nnnc3c3ccccc23)CC1   5.586   \n",
       "3     TRAIN_0003  Cc1ccc(-c2ccc(-n3nc(C)c(S(=O)(=O)N4CCN(C5CCCCC...   5.710   \n",
       "4     TRAIN_0004                Cc1ccc2c(c1)N(C(=O)c1ccncc1)CC(C)O2  93.270   \n",
       "...          ...                                                ...     ...   \n",
       "3493  TRAIN_3493     Cn1nc(CNC(=O)Cn2nc(C(F)(F)F)c3c2CCC3)c(Cl)c1Cl   1.556   \n",
       "3494  TRAIN_3494  CCn1[nH]cc/c1=N\\C(=O)c1nn(-c2ccccc2)c(=O)c2ccc...  35.560   \n",
       "3495  TRAIN_3495                       CCOC(=O)CCCc1nc2cc(N)ccc2n1C  56.150   \n",
       "3496  TRAIN_3496                     Nc1cc(C(=O)OCCC2CCOC2=O)cnc1Cl   0.030   \n",
       "3497  TRAIN_3497                   COc1ccc(-c2nc(Cc3ccccc3)sc2C)cc1   0.450   \n",
       "\n",
       "         HLM  AlogP  Molecular_Weight  Num_H_Acceptors  Num_H_Donors  \\\n",
       "0     50.680  3.259           400.495                5             2   \n",
       "1     50.590  2.169           301.407                2             1   \n",
       "2     80.892  1.593           297.358                5             0   \n",
       "3      2.000  4.771           494.652                6             0   \n",
       "4     99.990  2.335           268.310                3             0   \n",
       "...      ...    ...               ...              ...           ...   \n",
       "3493   3.079  3.409           396.195                3             1   \n",
       "3494  47.630  1.912           359.381                4             1   \n",
       "3495   1.790  1.941           261.320                3             1   \n",
       "3496   2.770  0.989           284.696                5             1   \n",
       "3497   2.650  4.321           295.399                2             0   \n",
       "\n",
       "      Num_RotatableBonds   LogD  Molecular_PolarSurfaceArea  \n",
       "0                      8  3.259                      117.37  \n",
       "1                      2  2.172                       73.47  \n",
       "2                      3  1.585                       62.45  \n",
       "3                      5  3.475                       92.60  \n",
       "4                      1  2.337                       42.43  \n",
       "...                  ...    ...                         ...  \n",
       "3493                   5  3.409                       64.74  \n",
       "3494                   3  1.844                       77.37  \n",
       "3495                   6  2.124                       70.14  \n",
       "3496                   5  0.989                       91.51  \n",
       "3497                   4  4.321                       50.36  \n",
       "\n",
       "[3498 rows x 11 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "15853da7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('c', 39802), ('C', 26001), ('(', 14796), (')', 14796), ('1', 10300)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_counter.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb90978",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, ntoken, d_model, nhead, d_hid, nlayers, dropout = 0.2):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            ntoken (int): Token 개수. (32+1)개\n",
    "            d_model (int): embedding dimension과 같음\n",
    "            d_hid (int): \n",
    "            nlayers (int):\n",
    "            dropout (float): \n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.encoder = nn.Embedding(ntoken, d_model)\n",
    "        self.d_model = d_model\n",
    "        self.decoder = nn.Linear(d_model, 1)  # MLM, HLM 값 하나를 예측\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            src (Tensor): shape ``[seq_len, batch_size]``\n",
    "        Returns:\n",
    "            output (Tensor): shape ``[seq_len, batch_size, ntoken]``\n",
    "        \"\"\"\n",
    "        src = self.encoder(src) * math.sqrt(self.d_model)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src)\n",
    "        output = self.decoder(output)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e37d4e8",
   "metadata": {},
   "source": [
    "마스킹은 필요없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c450f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            d_model (int): \n",
    "            dropout (float): \n",
    "            max_len (int): \n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x (Tensor): shape ``[seq_len, batch_size, embedding_dim]``\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041766dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    def __init__(self, tokens_counter):\n",
    "        self.tokens_counter = tokens_counter\n",
    "    \n",
    "    def token_mapping(self):\n",
    "        tokens_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cac499",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = WikiText2(split='train')\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "vocab = build_vocab_from_iterator(map(tokenizer, train_iter), specials=['<unk>'])\n",
    "vocab.set_default_index(vocab['<unk>'])\n",
    "\n",
    "def data_process(raw_text_iter: dataset.IterableDataset) -> Tensor:\n",
    "    \"\"\"Converts raw text into a flat Tensor.\"\"\"\n",
    "    data = [torch.tensor(vocab(tokenizer(item)), dtype=torch.long) for item in raw_text_iter]\n",
    "    return torch.cat(tuple(filter(lambda t: t.numel() > 0, data)))\n",
    "\n",
    "# ``train_iter`` was \"consumed\" by the process of building the vocab,\n",
    "# so we have to create it again\n",
    "train_iter, val_iter, test_iter = WikiText2()\n",
    "train_data = data_process(train_iter)\n",
    "val_data = data_process(val_iter)\n",
    "test_data = data_process(test_iter)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def batchify(data: Tensor, bsz: int) -> Tensor:\n",
    "    \"\"\"Divides the data into ``bsz`` separate sequences, removing extra elements\n",
    "    that wouldn't cleanly fit.\n",
    "\n",
    "    Arguments:\n",
    "        data: Tensor, shape ``[N]``\n",
    "        bsz: int, batch size\n",
    "\n",
    "    Returns:\n",
    "        Tensor of shape ``[N // bsz, bsz]``\n",
    "    \"\"\"\n",
    "    seq_len = data.size(0) // bsz\n",
    "    data = data[:seq_len * bsz]\n",
    "    data = data.view(bsz, seq_len).t().contiguous()\n",
    "    return data.to(device)\n",
    "\n",
    "batch_size = 20\n",
    "eval_batch_size = 10\n",
    "train_data = batchify(train_data, batch_size)  # shape [seq_len, batch_size]\n",
    "val_data = batchify(val_data, eval_batch_size)\n",
    "test_data = batchify(test_data, eval_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c37bfe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72ce4a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b8ae51c",
   "metadata": {},
   "source": [
    "https://discuss.pytorch.org/t/how-to-add-padding-mask-to-nn-transformerencoder-module/63390/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b993513f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "q = torch.randn(3, 1, 10) # source sequence length 3, batch size 1, embedding size 10\n",
    "attn = nn.MultiheadAttention(10, 1) # embedding size 10, one head\n",
    "res = attn(q, q, q) # self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a927ac18",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.zeros(1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "072e3901",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask[0][-1] = float('-inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "508db1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.zeros(1, 3, dtype=torch.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "dc812695",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask[0][-1] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "7d5927d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False,  True]])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "33ceafd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_mask, w = attn(q, q, q, key_padding_mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "459cc39f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "9e584860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0159, 0.1173, 0.8668])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(torch.FloatTensor([2,4,6]), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "7ceb44e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4534, 0.5466, 0.0000],\n",
       "         [0.8158, 0.1842, 0.0000],\n",
       "         [0.6922, 0.3078, 0.0000]]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "a5a4a23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "res, w =attn(q,q,q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "c0102354",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.zeros(3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "a2ec15fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[-1] = float('-inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "eae1a306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [-inf, -inf, -inf]])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "f1922e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = F.softmax(test, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "63568853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "f09753e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [nan, nan, nan]])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(res, torch.ones(3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "51447a0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5308,  0.5410,  0.4923, -0.3016, -0.1482,  0.2765,  0.4337,\n",
       "          -0.0224,  0.3547, -0.0359]],\n",
       "\n",
       "        [[ 0.5308,  0.5410,  0.4923, -0.3016, -0.1482,  0.2765,  0.4337,\n",
       "          -0.0224,  0.3547, -0.0359]],\n",
       "\n",
       "        [[ 0.5308,  0.5410,  0.4923, -0.3016, -0.1482,  0.2765,  0.4337,\n",
       "          -0.0224,  0.3547, -0.0359]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "5e33939d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "59e5a35f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-inf, -inf, -inf]])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f2d40f66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[nan, nan, nan]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(mask, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1f821e48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.5008, -0.9272,  0.2531, -1.0852,  0.2230,  0.6262, -0.0557,\n",
       "          -1.4180, -0.3587, -0.8511]],\n",
       "\n",
       "        [[ 0.8764, -0.8869,  0.4847,  1.3660, -1.8363,  0.2446, -0.5027,\n",
       "           0.6274, -0.2760, -0.0792]],\n",
       "\n",
       "        [[-0.2222,  0.5592,  0.8395,  1.0963, -1.5894,  0.4925, -0.2025,\n",
       "          -0.4314, -1.7024, -0.4290]]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7673b37b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1048, -0.1434, -0.1923, -0.3875, -0.1883,  0.0326,  0.4077,\n",
       "           0.2217, -0.1304, -0.0842]],\n",
       "\n",
       "        [[ 0.2626,  0.0537, -0.0712, -0.5399, -0.2916,  0.1719,  0.4479,\n",
       "          -0.0824, -0.1685,  0.0877]],\n",
       "\n",
       "        [[ 0.2088, -0.0135, -0.1125, -0.4879, -0.2563,  0.1244,  0.4342,\n",
       "           0.0213, -0.1555,  0.0291]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7296b5f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0612,  0.1095, -0.3077,  0.2431,  0.1704, -0.3031,  0.0206,\n",
       "          -0.3229, -0.2638,  0.2673]],\n",
       "\n",
       "        [[ 0.1361,  0.0900, -0.2317,  0.3017,  0.2159, -0.3380,  0.0759,\n",
       "          -0.2576, -0.2895,  0.2333]],\n",
       "\n",
       "        [[ 0.0206,  0.1660, -0.2280,  0.3331,  0.1539, -0.3960,  0.0576,\n",
       "          -0.2094, -0.2356,  0.2878]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedfabe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d08a0b2a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sz' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [67]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m mask \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39mtriu(torch\u001b[38;5;241m.\u001b[39mones(\u001b[43msz\u001b[49m, sz)) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      2\u001b[0m mask \u001b[38;5;241m=\u001b[39m mask\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mmasked_fill(mask \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-inf\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;241m.\u001b[39mmasked_fill(mask \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;241m0.0\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sz' is not defined"
     ]
    }
   ],
   "source": [
    "mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4acd3289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 10])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "98f2b82b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[1].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": ".venv_ds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
